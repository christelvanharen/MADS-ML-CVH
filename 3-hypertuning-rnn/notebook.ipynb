{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.5'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from mltrainer import rnn_models, Trainer\n",
    "from torch import optim\n",
    "\n",
    "from mads_datasets import datatools\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.pytorch\n",
    "import mlflow\n",
    "import mltrainer\n",
    "mltrainer.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Iterators\n",
    "We will be using an interesting dataset. [link](https://tev.fbk.eu/resources/smartwatch)\n",
    "\n",
    "From the site:\n",
    "> The SmartWatch Gestures Dataset has been collected to evaluate several gesture recognition algorithms for interacting with mobile applications using arm gestures. Eight different users performed twenty repetitions of twenty different gestures, for a total of 3200 sequences. Each sequence contains acceleration data from the 3-axis accelerometer of a first generation Sony SmartWatch™, as well as timestamps from the different clock sources available on an Android device. The smartwatch was worn on the user's right wrist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-25 22:16:23.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/christelvanharen/.cache/mads_datasets/gestures\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 2600/2600 [00:10<00:00, 259.82it/s]\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 651/651 [00:02<00:00, 260.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "from mltrainer.preprocessors import PaddedPreprocessor\n",
    "preprocessor = PaddedPreprocessor()\n",
    "\n",
    "gesturesdatasetfactory = DatasetFactoryProvider.create_factory(DatasetType.GESTURES)\n",
    "streamers = gesturesdatasetfactory.create_datastreamer(batchsize=32, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30, 3]),\n",
       " tensor([10, 16,  8, 11,  5,  3,  9,  6, 15, 11, 12, 18, 15, 13,  8, 18,  1,  8,\n",
       "         11, 14,  0,  6,  7, 10, 18, 14,  7,  3,  7,  6, 12, 18]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()\n",
    "x, y = next(iter(trainstreamer))\n",
    "x.shape, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make sense of the shape?\n",
    "What does it mean that the shapes are sometimes (32, 27, 3), but a second time might look like (32, 30, 3)? In other words, the second (or first, if you insist on starting at 0) dimension changes. Why is that? How does the model handle this? Do you think this is already padded, or still has to be padded?\n",
    "\n",
    "\n",
    "# 2 Excercises\n",
    "Lets test a basemodel, and try to improve upon that.\n",
    "\n",
    "Fill the gestures.gin file with relevant settings for `input_size`, `hidden_size`, `num_layers` and `horizon` (which, in our case, will be the number of classes...)\n",
    "\n",
    "As a rule of thumbs: start lower than you expect to need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mltrainer import TrainerSettings, ReportTypes\n",
    "from mltrainer.metrics import Accuracy\n",
    "\n",
    "accuracy = Accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn_models.BaseRNN(\n",
    "    input_size=3,\n",
    "    hidden_size=64,\n",
    "    num_layers=1,\n",
    "    horizon=20,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model. What is the output shape you need? Remember, we are doing classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 20])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the accuracy? What would you expect from blind guessing?\n",
    "\n",
    "Check shape of `y` and `yhat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 20]), torch.Size([32]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look at the output of yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0710,  0.1273,  0.0120, -0.1085,  0.0478,  0.0258,  0.0286,  0.1333,\n",
       "         0.1436,  0.1596,  0.1096,  0.1469, -0.0045, -0.0848,  0.0081,  0.1249,\n",
       "        -0.1494, -0.0020, -0.1531,  0.0009], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does this make sense to you? If you are unclear, go back to the classification problem with the MNIST, where we had 10 classes.\n",
    "\n",
    "We have a classification problem, so we need Cross Entropy Loss.\n",
    "Remember, [this has a softmax built in](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9946, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss = loss_fn(yhat, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")\n",
    "\n",
    "# on my mac, at least for the BaseRNN model, mps does not speed up training\n",
    "# probably because the overhead of copying the data to the GPU is too high\n",
    "# so i override the device to cpu\n",
    "device = \"cpu\"\n",
    "# however, it might speed up training for larger models, with more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the settings for the trainer and the different types of logging you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epochs: 80\n",
       "metrics: [Accuracy]\n",
       "logdir: gestures\n",
       "train_steps: 81\n",
       "valid_steps: 20\n",
       "reporttypes: [<ReportTypes.TOML: 'TOML'>, <ReportTypes.TENSORBOARD: 'TENSORBOARD'>, <ReportTypes.MLFLOW: 'MLFLOW'>]\n",
       "optimizer_kwargs: {'lr': 0.001, 'weight_decay': 1e-05}\n",
       "scheduler_kwargs: {'factor': 0.5, 'patience': 4}\n",
       "earlystop_kwargs: {'save': False, 'verbose': True, 'patience': 8, 'delta': 0.0001}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = TrainerSettings(\n",
    "    epochs=80,  # allow longer training; early stopping will end sooner\n",
    "    metrics=[accuracy],\n",
    "    logdir=Path(\"gestures\"),\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TOML, ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "    scheduler_kwargs={\"factor\": 0.5, \"patience\": 4},\n",
    "    earlystop_kwargs={\n",
    "        \"save\": False,\n",
    "        \"verbose\": True,\n",
    "        \"patience\": 8,\n",
    "        \"delta\": 1e-4,\n",
    "    },\n",
    ")\n",
    "settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Tuple, Sequence, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class RNNConfig:\n",
    "    input_size: int\n",
    "    hidden_size: int\n",
    "    num_layers: int\n",
    "    output_size: int\n",
    "    dropout: float = 0.0\n",
    "    bidirectional: bool = False\n",
    "    pooling: str = \"mean\"\n",
    "\n",
    "    @property\n",
    "    def hidden_factor(self) -> int:\n",
    "        return 2 if self.bidirectional else 1\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        data = asdict(self)\n",
    "        data[\"pooling\"] = self.pooling\n",
    "        return data\n",
    "\n",
    "@dataclass\n",
    "class ConvRNNConfig(RNNConfig):\n",
    "    conv_channels: Tuple[int, ...] = (32, 64)\n",
    "    conv_kernel: int = 3\n",
    "    conv_dropout: float = 0.1\n",
    "\n",
    "def infer_lengths(batch: Tensor) -> Tensor:\n",
    "    mask = batch.abs().sum(dim=-1) > 0\n",
    "    lengths = mask.sum(dim=-1)\n",
    "    lengths[lengths == 0] = batch.size(1)\n",
    "    return lengths\n",
    "\n",
    "def pool_sequence(outputs: Tensor, lengths: Tensor, pooling: str) -> Tensor:\n",
    "    if pooling not in {\"last\", \"mean\"}:\n",
    "        raise ValueError(f\"Unknown pooling mode: {pooling}\")\n",
    "    batch_indices = torch.arange(outputs.size(0), device=outputs.device)\n",
    "    if pooling == \"last\":\n",
    "        last_indices = torch.clamp(lengths - 1, min=0)\n",
    "        return outputs[batch_indices, last_indices]\n",
    "    mask = (torch.arange(outputs.size(1), device=outputs.device).unsqueeze(0)\n",
    "            < lengths.unsqueeze(1))\n",
    "    masked = outputs * mask.unsqueeze(-1)\n",
    "    summed = masked.sum(dim=1)\n",
    "    return summed / lengths.unsqueeze(-1)\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, config: RNNConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            num_layers=config.num_layers,\n",
    "            dropout=config.dropout if config.num_layers > 1 else 0.0,\n",
    "            bidirectional=config.bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(config.hidden_size * config.hidden_factor, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        lengths = infer_lengths(x)\n",
    "        outputs, _ = self.rnn(x)\n",
    "        pooled = pool_sequence(outputs, lengths, self.config.pooling)\n",
    "        pooled = self.dropout(pooled)\n",
    "        return self.fc(pooled)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, config: RNNConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=config.input_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            num_layers=config.num_layers,\n",
    "            dropout=config.dropout if config.num_layers > 1 else 0.0,\n",
    "            bidirectional=config.bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(config.hidden_size * config.hidden_factor, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        lengths = infer_lengths(x)\n",
    "        outputs, _ = self.rnn(x)\n",
    "        pooled = pool_sequence(outputs, lengths, self.config.pooling)\n",
    "        pooled = self.dropout(pooled)\n",
    "        return self.fc(pooled)\n",
    "\n",
    "class ConvGRUClassifier(nn.Module):\n",
    "    def __init__(self, config: ConvRNNConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        conv_layers: Sequence[nn.Module] = []\n",
    "        in_channels = config.input_size\n",
    "        for out_channels in config.conv_channels:\n",
    "            conv_layers.extend(\n",
    "                [\n",
    "                    nn.Conv1d(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=config.conv_kernel,\n",
    "                        padding=config.conv_kernel // 2,\n",
    "                    ),\n",
    "                    nn.BatchNorm1d(out_channels),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Dropout(config.conv_dropout),\n",
    "                ]\n",
    "            )\n",
    "            in_channels = out_channels\n",
    "        self.feature_extractor = nn.Sequential(*conv_layers)\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=in_channels,\n",
    "            hidden_size=config.hidden_size,\n",
    "            num_layers=config.num_layers,\n",
    "            dropout=config.dropout if config.num_layers > 1 else 0.0,\n",
    "            bidirectional=config.bidirectional,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.fc = nn.Linear(config.hidden_size * config.hidden_factor, config.output_size)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        lengths = infer_lengths(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        outputs, _ = self.rnn(x)\n",
    "        pooled = pool_sequence(outputs, lengths, self.config.pooling)\n",
    "        pooled = self.dropout(pooled)\n",
    "        return self.fc(pooled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter templates\n",
    "The experiments below instantiate `RNNConfig` and `ConvRNNConfig` objects to explore GRU, LSTM, and Conv+GRU variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-25 22:16:36.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures/20250925-221636\u001b[0m\n",
      "\u001b[32m2025-09-25 22:16:36.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.37it/s]\n",
      "\u001b[32m2025-09-25 22:16:40.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.2277 test 1.4582 metric ['0.5141']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.97it/s]\n",
      "\u001b[32m2025-09-25 22:16:43.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.8875 test 0.3702 metric ['0.9469']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 23.04it/s]\n",
      "\u001b[32m2025-09-25 22:16:47.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.2011 test 0.1096 metric ['0.9859']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.86it/s]\n",
      "\u001b[32m2025-09-25 22:16:51.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.0805 test 0.1037 metric ['0.9828']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.98it/s]\n",
      "\u001b[32m2025-09-25 22:16:55.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.0792 test 0.0592 metric ['0.9922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.77it/s]\n",
      "\u001b[32m2025-09-25 22:16:59.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0317 test 0.0441 metric ['0.9953']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 21.78it/s]\n",
      "\u001b[32m2025-09-25 22:17:03.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0180 test 0.0333 metric ['0.9969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.68it/s]\n",
      "\u001b[32m2025-09-25 22:17:07.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0112 test 0.0301 metric ['0.9922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.92it/s]\n",
      "\u001b[32m2025-09-25 22:17:11.033\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0287 test 0.0445 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:11.034\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0445.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.45it/s]\n",
      "\u001b[32m2025-09-25 22:17:14.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0102 test 0.0345 metric ['0.9969']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:14.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0345.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 21.34it/s]\n",
      "\u001b[32m2025-09-25 22:17:19.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0062 test 0.0349 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:19.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0349.Counter 3/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 21.95it/s]\n",
      "\u001b[32m2025-09-25 22:17:23.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0102 test 0.0380 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:23.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0380.Counter 4/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.36it/s]\n",
      "\u001b[32m2025-09-25 22:17:27.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0114 test 0.0560 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:27.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0560.Counter 5/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.77it/s]\n",
      "\u001b[32m2025-09-25 22:17:30.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0112 test 0.0405 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:30.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0405.Counter 6/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.97it/s]\n",
      "\u001b[32m2025-09-25 22:17:34.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0056 test 0.0399 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:34.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0301, current loss 0.0399.Counter 7/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.55it/s]\n",
      "\u001b[32m2025-09-25 22:17:38.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.0038 test 0.0238 metric ['0.9969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 23.25it/s]\n",
      "\u001b[32m2025-09-25 22:17:42.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 16 train 0.0041 test 0.0386 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:42.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0386.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.86it/s]\n",
      "\u001b[32m2025-09-25 22:17:46.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 17 train 0.0033 test 0.0379 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:46.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0379.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.44it/s]\n",
      "\u001b[32m2025-09-25 22:17:50.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 18 train 0.0032 test 0.0392 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:50.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0392.Counter 3/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.81it/s]\n",
      "\u001b[32m2025-09-25 22:17:54.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 19 train 0.0025 test 0.0389 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:54.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0389.Counter 4/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.89it/s]\n",
      "\u001b[32m2025-09-25 22:17:57.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 20 train 0.0027 test 0.0383 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:17:57.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0383.Counter 5/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 20.57it/s]\n",
      "\u001b[32m2025-09-25 22:18:02.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 21 train 0.0028 test 0.0382 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:18:02.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0382.Counter 6/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 21.08it/s]\n",
      "\u001b[32m2025-09-25 22:18:06.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 22 train 0.0023 test 0.0379 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:18:06.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0379.Counter 7/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:03<00:00, 22.79it/s]\n",
      "\u001b[32m2025-09-25 22:18:10.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 23 train 0.0026 test 0.0392 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:18:10.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0392.Counter 8/8.\u001b[0m\n",
      "\u001b[32m2025-09-25 22:18:10.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-09-25 22:18:10.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mearly_stopping_save was false, using latest model.Set to true to retrieve best model.\u001b[0m\n",
      " 29%|\u001b[38;2;30;71;6m██▉       \u001b[0m| 23/80 [01:34<03:53,  4.09s/it]\n",
      "\u001b[32m2025-09-25 22:18:43.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures/20250925-221843\u001b[0m\n",
      "\u001b[32m2025-09-25 22:18:43.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigru_mean_pool: validation accuracy 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.36it/s]\n",
      "\u001b[32m2025-09-25 22:18:48.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.1446 test 1.5029 metric ['0.4094']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.88it/s]\n",
      "\u001b[32m2025-09-25 22:18:53.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 1.1271 test 0.8334 metric ['0.7266']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.76it/s]\n",
      "\u001b[32m2025-09-25 22:18:58.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.5673 test 0.2940 metric ['0.9516']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.74it/s]\n",
      "\u001b[32m2025-09-25 22:19:03.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.2185 test 0.1417 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.50it/s]\n",
      "\u001b[32m2025-09-25 22:19:08.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.1048 test 0.0984 metric ['0.9828']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.65it/s]\n",
      "\u001b[32m2025-09-25 22:19:14.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0884 test 0.1016 metric ['0.9766']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:19:14.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0984, current loss 0.1016.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.54it/s]\n",
      "\u001b[32m2025-09-25 22:19:19.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0441 test 0.0663 metric ['0.9844']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.74it/s]\n",
      "\u001b[32m2025-09-25 22:19:24.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0361 test 0.0591 metric ['0.9922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.36it/s]\n",
      "\u001b[32m2025-09-25 22:19:29.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0214 test 0.0536 metric ['0.9906']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.59it/s]\n",
      "\u001b[32m2025-09-25 22:19:34.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0280 test 0.0639 metric ['0.9812']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:19:34.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0536, current loss 0.0639.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.30it/s]\n",
      "\u001b[32m2025-09-25 22:19:39.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0309 test 0.0611 metric ['0.9891']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:19:39.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0536, current loss 0.0611.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.38it/s]\n",
      "\u001b[32m2025-09-25 22:19:45.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0370 test 0.0530 metric ['0.9953']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.59it/s]\n",
      "\u001b[32m2025-09-25 22:19:50.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0250 test 0.1173 metric ['0.9672']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:19:50.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0530, current loss 0.1173.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 17.12it/s]\n",
      "\u001b[32m2025-09-25 22:19:55.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0268 test 0.0498 metric ['0.9906']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 16.60it/s]\n",
      "\u001b[32m2025-09-25 22:20:00.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0222 test 0.0774 metric ['0.9844']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:20:00.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0498, current loss 0.0774.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [10:20<00:00,  7.66s/it]\n",
      "\u001b[32m2025-09-25 22:30:22.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.0124 test 0.0259 metric ['0.9953']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:07<00:00, 11.55it/s]it]\n",
      "\u001b[32m2025-09-25 22:30:30.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 16 train 0.0072 test 0.0460 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:30:30.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0259, current loss 0.0460.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:10<00:00,  8.07it/s]it]\n",
      "\u001b[32m2025-09-25 22:30:41.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 17 train 0.0059 test 0.0465 metric ['0.9922']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:30:41.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0259, current loss 0.0465.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.49it/s]t] \n",
      "\u001b[32m2025-09-25 22:30:51.951\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 18 train 0.0033 test 0.0495 metric ['0.9922']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:30:51.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0259, current loss 0.0495.Counter 3/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [12:01<00:00,  8.90s/it]t]\n",
      "\u001b[32m2025-09-25 22:42:53.659\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 19 train 0.0029 test 0.0398 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:42:53.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0259, current loss 0.0398.Counter 4/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:06<00:00, 12.24it/s]it]\n",
      "\u001b[32m2025-09-25 22:43:01.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 20 train 0.0034 test 0.0238 metric ['0.9953']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.78it/s]it]\n",
      "\u001b[32m2025-09-25 22:43:11.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 21 train 0.0017 test 0.0504 metric ['0.9922']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:43:11.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0504.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:07<00:00, 10.63it/s]it]\n",
      "\u001b[32m2025-09-25 22:43:19.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 22 train 0.0024 test 0.0691 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-09-25 22:43:19.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0691.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:42<00:00, 13.11s/it]t] \n",
      "\u001b[32m2025-09-25 23:01:02.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 23 train 0.0019 test 0.0278 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 23:01:02.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0278.Counter 3/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [13:49<00:00, 10.25s/it]it]\n",
      "\u001b[32m2025-09-25 23:14:52.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 24 train 0.0027 test 0.0525 metric ['0.9891']\u001b[0m\n",
      "\u001b[32m2025-09-25 23:14:52.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0525.Counter 4/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.30it/s]it]\n",
      "\u001b[32m2025-09-25 23:15:03.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 25 train 0.0030 test 0.0427 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-25 23:15:03.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0427.Counter 5/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:09<00:00,  8.78it/s]it]\n",
      "\u001b[32m2025-09-25 23:15:13.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 26 train 0.0016 test 0.0450 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-25 23:15:13.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0450.Counter 6/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:08<00:00, 10.10it/s]it]\n",
      "\u001b[32m2025-09-25 23:15:22.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 27 train 0.0013 test 0.0462 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-25 23:15:22.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0462.Counter 7/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [15:11<00:00, 11.25s/it]it]\n",
      "\u001b[32m2025-09-25 23:30:34.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 28 train 0.0021 test 0.0273 metric ['0.9969']\u001b[0m\n",
      "\u001b[32m2025-09-25 23:30:34.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0238, current loss 0.0273.Counter 8/8.\u001b[0m\n",
      "\u001b[32m2025-09-25 23:30:34.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-09-25 23:30:34.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mearly_stopping_save was false, using latest model.Set to true to retrieve best model.\u001b[0m\n",
      " 35%|\u001b[38;2;30;71;6m███▌      \u001b[0m| 28/80 [1:11:50<2:13:25, 153.96s/it]\n",
      "\u001b[32m2025-09-25 23:46:43.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to gestures/20250925-234643\u001b[0m\n",
      "\u001b[32m2025-09-25 23:46:43.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilstm_dropout: validation accuracy 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:02<00:00, 12.62s/it]\n",
      "\u001b[32m2025-09-26 00:03:45.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 2.0988 test 1.1628 metric ['0.5953']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [16:30<00:00, 12.23s/it]/it]\n",
      "\u001b[32m2025-09-26 00:20:16.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.7281 test 0.2803 metric ['0.9203']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [10:21<00:00,  7.67s/it]/it]\n",
      "\u001b[32m2025-09-26 00:30:38.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3049 test 0.1582 metric ['0.9641']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:08<00:00,  9.51it/s]it] \n",
      "\u001b[32m2025-09-26 00:30:47.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.1802 test 0.1024 metric ['0.9703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:08<00:00,  9.37it/s]it]\n",
      "\u001b[32m2025-09-26 00:30:56.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.1182 test 0.0890 metric ['0.9719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:07<00:00, 10.31it/s]t] \n",
      "\u001b[32m2025-09-26 00:31:05.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 5 train 0.0970 test 0.1420 metric ['0.9641']\u001b[0m\n",
      "\u001b[32m2025-09-26 00:31:05.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0890, current loss 0.1420.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:20<00:00, 12.85s/it]t]\n",
      "\u001b[32m2025-09-26 00:48:26.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 6 train 0.0927 test 0.0651 metric ['0.9844']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:49<00:00, 13.20s/it]/it]\n",
      "\u001b[32m2025-09-26 01:06:16.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 7 train 0.0602 test 0.0400 metric ['0.9922']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [16:10<00:00, 11.98s/it]s/it]\n",
      "\u001b[32m2025-09-26 01:22:26.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 8 train 0.0386 test 0.0598 metric ['0.9875']\u001b[0m\n",
      "\u001b[32m2025-09-26 01:22:26.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0400, current loss 0.0598.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:15<00:00, 12.78s/it]s/it]\n",
      "\u001b[32m2025-09-26 01:39:42.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 9 train 0.0551 test 0.0440 metric ['0.9859']\u001b[0m\n",
      "\u001b[32m2025-09-26 01:39:42.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0400, current loss 0.0440.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [16:37<00:00, 12.31s/it]9s/it]\n",
      "\u001b[32m2025-09-26 01:56:20.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 10 train 0.0370 test 0.0509 metric ['0.9906']\u001b[0m\n",
      "\u001b[32m2025-09-26 01:56:20.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0400, current loss 0.0509.Counter 3/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:02<00:00, 12.62s/it]3s/it]\n",
      "\u001b[32m2025-09-26 02:13:22.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 11 train 0.0268 test 0.0120 metric ['0.9969']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [16:32<00:00, 12.25s/it]7s/it]\n",
      "\u001b[32m2025-09-26 02:29:55.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 12 train 0.0404 test 0.0580 metric ['0.9906']\u001b[0m\n",
      "\u001b[32m2025-09-26 02:29:55.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0580.Counter 1/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:27<00:00, 12.93s/it]6s/it]\n",
      "\u001b[32m2025-09-26 02:47:23.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 13 train 0.0388 test 0.0338 metric ['0.9953']\u001b[0m\n",
      "\u001b[32m2025-09-26 02:47:23.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0338.Counter 2/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [17:05<00:00, 12.66s/it]2s/it]\n",
      "\u001b[32m2025-09-26 03:04:28.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 14 train 0.0320 test 0.0551 metric ['0.9906']\u001b[0m\n",
      "\u001b[32m2025-09-26 03:04:28.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0551.Counter 3/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [15:43<00:00, 11.64s/it]2s/it]\n",
      "\u001b[32m2025-09-26 03:20:12.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 15 train 0.0197 test 0.0254 metric ['0.9891']\u001b[0m\n",
      "\u001b[32m2025-09-26 03:20:12.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0254.Counter 4/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [15:30<00:00, 11.48s/it]1s/it]\n",
      "\u001b[32m2025-09-26 03:35:42.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 16 train 0.0221 test 0.0480 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-26 03:35:42.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0480.Counter 5/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 18.58it/s]7s/it]\n",
      "\u001b[32m2025-09-26 03:51:43.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 17 train 0.0136 test 0.0172 metric ['0.9938']\u001b[0m\n",
      "\u001b[32m2025-09-26 03:51:43.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0172.Counter 6/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [00:04<00:00, 18.47it/s]4s/it]\n",
      "\u001b[32m2025-09-26 03:51:48.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 18 train 0.0088 test 0.0257 metric ['0.9969']\u001b[0m\n",
      "\u001b[32m2025-09-26 03:51:48.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0257.Counter 7/8.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 81/81 [08:16<00:00,  6.13s/it]8s/it]\n",
      "\u001b[32m2025-09-26 04:00:06.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 19 train 0.0116 test 0.0321 metric ['0.9922']\u001b[0m\n",
      "\u001b[32m2025-09-26 04:00:06.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.0120, current loss 0.0321.Counter 8/8.\u001b[0m\n",
      "\u001b[32m2025-09-26 04:00:06.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mInterrupting loop due to early stopping patience.\u001b[0m\n",
      "\u001b[32m2025-09-26 04:00:06.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mloop\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mearly_stopping_save was false, using latest model.Set to true to retrieve best model.\u001b[0m\n",
      " 24%|\u001b[38;2;30;71;6m██▍       \u001b[0m| 19/80 [4:13:22<13:33:29, 800.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_bigru: validation accuracy 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('bigru_mean_pool', 0.99375),\n",
       " ('bilstm_dropout', 0.99375),\n",
       " ('conv_bigru', 0.99375)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dataclasses import asdict\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "# Use a writable location for the MLflow database\n",
    "mlflow_db_path = Path.cwd() / \"mlflow.db\"\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{mlflow_db_path}\")\n",
    "\n",
    "registry_root = (Path(\"mlruns\").resolve() / \"model-registry\")\n",
    "registry_root.mkdir(parents=True, exist_ok=True)\n",
    "mlflow.set_registry_uri(f\"file:{registry_root}\")\n",
    "mlflow.set_experiment(\"gestures\")\n",
    "\n",
    "modeldir = Path(\"gestures\").resolve()\n",
    "modeldir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def iterate_dataset(ds):\n",
    "    stream = ds.stream()\n",
    "    for _ in range(len(ds)):\n",
    "        yield next(stream)\n",
    "\n",
    "def evaluate_accuracy(model: nn.Module, dataset) -> float:\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in iterate_dataset(dataset):\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return correct / total\n",
    "\n",
    "experiment_results: List[dict] = []\n",
    "\n",
    "def run_experiment(run_name: str, model_builder: Callable[[], nn.Module], config_dict: dict) -> float:\n",
    "    torch.manual_seed(42)\n",
    "    model = model_builder().to(device)\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        mlflow.set_tag(\"model\", run_name)\n",
    "        mlflow.set_tag(\"dev\", \"cvh\")\n",
    "        mlflow.log_params({**config_dict, \"epochs\": settings.epochs})\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            settings=settings,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optim.Adam,\n",
    "            traindataloader=train.stream(),\n",
    "            validdataloader=valid.stream(),\n",
    "            scheduler=optim.lr_scheduler.ReduceLROnPlateau,\n",
    "            device=device,\n",
    "        )\n",
    "        trainer.loop()\n",
    "        val_accuracy = evaluate_accuracy(model, valid)\n",
    "        mlflow.log_metric(\"final_val_accuracy\", val_accuracy)\n",
    "        example_batch, _ = next(valid.stream())\n",
    "        example_tensor = example_batch[:1].to(device)\n",
    "        with torch.no_grad():\n",
    "            prediction = model(example_tensor)\n",
    "        example_numpy = example_batch[:1].cpu().numpy()\n",
    "        signature = infer_signature(example_numpy, prediction.detach().cpu().numpy())\n",
    "        model_alias = f\"{run_name}-model\"\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            name=model_alias,\n",
    "            input_example=example_numpy,\n",
    "            signature=signature,\n",
    "        )\n",
    "        if not settings.earlystop_kwargs[\"save\"]:\n",
    "            tag = datetime.now().strftime(\"%Y%m%d-%H%M-\")\n",
    "            model_path = modeldir / f\"{tag}{run_name}.pt\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    experiment_results.append(\n",
    "        {\"run\": run_name, \"model\": config_dict.get(\"model_class\"), \"val_accuracy\": val_accuracy}\n",
    "    )\n",
    "    print(f\"{run_name}: validation accuracy {val_accuracy:.4f}\")\n",
    "    return val_accuracy\n",
    "\n",
    "gru_config = RNNConfig(\n",
    "    input_size=3,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    output_size=20,\n",
    "    dropout=0.3,\n",
    "    bidirectional=True,\n",
    "    pooling=\"mean\",\n",
    ")\n",
    "lstm_config = RNNConfig(\n",
    "    input_size=3,\n",
    "    hidden_size=160,\n",
    "    num_layers=2,\n",
    "    output_size=20,\n",
    "    dropout=0.35,\n",
    "    bidirectional=True,\n",
    "    pooling=\"mean\",\n",
    ")\n",
    "conv_gru_config = ConvRNNConfig(\n",
    "    input_size=3,\n",
    "    conv_channels=(32, 64),\n",
    "    conv_kernel=5,\n",
    "    conv_dropout=0.2,\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    output_size=20,\n",
    "    dropout=0.3,\n",
    "    bidirectional=True,\n",
    "    pooling=\"mean\",\n",
    ")\n",
    "\n",
    "experiments: List[Tuple[str, Callable[[], nn.Module], dict]] = [\n",
    "    (\n",
    "        \"bigru_mean_pool\",\n",
    "        lambda: GRUClassifier(gru_config),\n",
    "        {**gru_config.to_dict(), \"model_class\": \"GRUClassifier\"},\n",
    "    ),\n",
    "    (\n",
    "        \"bilstm_dropout\",\n",
    "        lambda: LSTMClassifier(lstm_config),\n",
    "        {**lstm_config.to_dict(), \"model_class\": \"LSTMClassifier\"},\n",
    "    ),\n",
    "    (\n",
    "        \"conv_bigru\",\n",
    "        lambda: ConvGRUClassifier(conv_gru_config),\n",
    "        {**conv_gru_config.to_dict(), \"model_class\": \"ConvGRUClassifier\"},\n",
    "    ),\n",
    "]\n",
    "\n",
    "run_summaries = []\n",
    "for run_name, builder, cfg in experiments:\n",
    "    val_acc = run_experiment(run_name, builder, cfg)\n",
    "    run_summaries.append((run_name, val_acc))\n",
    "\n",
    "sorted(run_summaries, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Results overview\n",
    "The cell above trains three variants (BiGRU, BiLSTM, Conv+BiGRU) and logs them to MLflow.\n",
    "You can re-run it after tweaking the configs to compare new experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "de650382-f209-4878-be3c-fac8906b5f64",
       "rows": [
        [
         "0",
         "bigru_mean_pool",
         "GRUClassifier",
         "0.99375"
        ],
        [
         "1",
         "bilstm_dropout",
         "LSTMClassifier",
         "0.99375"
        ],
        [
         "2",
         "conv_bigru",
         "ConvGRUClassifier",
         "0.99375"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>model</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bigru_mean_pool</td>\n",
       "      <td>GRUClassifier</td>\n",
       "      <td>0.99375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bilstm_dropout</td>\n",
       "      <td>LSTMClassifier</td>\n",
       "      <td>0.99375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>conv_bigru</td>\n",
       "      <td>ConvGRUClassifier</td>\n",
       "      <td>0.99375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               run              model  val_accuracy\n",
       "0  bigru_mean_pool      GRUClassifier       0.99375\n",
       "1   bilstm_dropout     LSTMClassifier       0.99375\n",
       "2       conv_bigru  ConvGRUClassifier       0.99375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy: 0.9938 (run=bigru_mean_pool, model=GRUClassifier)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not experiment_results:\n",
    "    raise RuntimeError(\"No experiments recorded yet. Run the training cell first.\")\n",
    "\n",
    "results_df = pd.DataFrame(experiment_results).sort_values(\"val_accuracy\", ascending=False)\n",
    "display(results_df)\n",
    "best_run = results_df.iloc[0]\n",
    "print(\n",
    "    f\"Best validation accuracy: {best_run.val_accuracy:.4f} (run={best_run.run}, model={best_run.model})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can launch `mlflow ui --backend-store-uri sqlite:///mlflow.db` to inspect the training curves and compare runs interactively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
